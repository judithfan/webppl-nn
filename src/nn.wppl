// Like mem, but cache key is only based on the first argument of the
// memoized function.
var mem1 = function(f) {
  globalStore.mem1Index = 1 + (globalStore.mem1Index || 0);
  var key = 'mem1-' + globalStore.mem1Index;
  return function(arg) {
    var stringedArg = key + util.serialize(arg);
    if (_.has(globalStore, stringedArg)) {
      return globalStore[stringedArg];
    } else {
      var val = apply(f, arguments);
      globalStore[stringedArg] = val;
      return val;
    }
  };
};

// This is a first attempt at providing a method for running bits of
// optimized programs. I think we can do more/better though.

// Calling the regular function `fn` evaluates the function, sampling
// from the target. Calling the result of withParams(params, fn)
// evaluates the function sampling from the guide using the parameters
// given by "params".

var withParams = function(params, fn) {
  return function() {
    var args = arguments;
    sample(Infer({params, method: 'forward', samples: 1, guide: true, model() {
      return ad.valueRec(apply(fn, args));
    }}));
  };
};

// ==================================================
// Model Parameters
// ==================================================

// By model parameter I mean a guide parameter that is included in a
// model by adding a prior distribution that is guided by a delta
// distribution, parameterized by the guide parameter. When optimizing
// the ELBO we can view optimization as performing maximum likelihood
// with regularization on the model parameters.

// WebPPL already has `modelParam` which does this for the case where
// the prior is an improper uniform over the reals. (This improper
// prior corresponded to performing no regularizing.)

// OBSERVATION: If we want model parameters to behave similarly to
// `param`, then fetching a parameter with a given name multiple times
// during the evaluation a model, should always return the same value.
// When optimizing the ELBO, this is automatically the case, since the
// guide is just a Delta on the parameter, and `param` will return the
// same value for a given name. However, if we were to follow the
// current implementation of `modelParam`, this wouldn't be the case
// for other algorithms. Imagine using HMC to do inference for a
// Bayesian neural network, and further that this network is used in
// more than one place in the model, where the sharing comes from the
// re-use of parameter names. Because we're no longer sampling from
// the guide, there is now nothing to induce sharing by name -- each
// call to `modelParam` will sample fresh parameters for the network
// from the prior. This consideration suggests the we ought to cache
// calls to `modelParam`. (Using the parameter name as the cache key.)
// This also makes sense from another perspective -- without such
// caching, every additional call to `modelParam` will add its own
// regularization term to the objective when optimizing the ELBO.

// This helper implements the pattern just described:

var __parameterModel = mem1(function(name, paramOpts, getPrior) {
  // getPrior is a function that returns a distribution instance. It
  // is passed the options that are passed to `param` to make it
  // possible to have the dimension of the prior match that of the
  // guide parameter.
  return sample(getPrior(paramOpts), {guide() {
    return Delta({v: param(paramOpts)});
  }});
});

var parameterModel = function(getPrior) {
  return function(paramOpts) {
    // TODO: Handle address based names.
    assert.ok(paramOpts.name, 'A name must be given.');
    return __parameterModel(paramOpts.name, paramOpts, getPrior);
  };
};

// Note that since it's not possible to sample from an improper prior,
// that fact that the result of sampling isn't cached (as discused
// above) is not a problem.
// var modelParam = paramModel(constF(ImproperUniform()));

// The function returned by e.g. modelParamL2(0.1) is analogous the
// WebPPL's `modelParam`.
var modelParamL2 = function(sigma) {
  return parameterModel(function(paramOpts) {
    var dims = paramOpts.dims;
    return dims ?
        TensorGaussian({mu: 0, sigma, dims}) :
        Gaussian({mu: 0, sigma});
  });
};

// TODO: One problem here is that one would expect `modelParam` to
// throw an error in the guide because it calls `sample`. However, if
// the value of the parameter has been cached, it's possible to call
// `modelParam` and successfully fetch the value. This is confusing.
// Perhaps `modelParam` should check whether its called from the
// guide, and error out if so.

// ==================================================
// Neural Networks
// ==================================================

var dims = function(x) {
  return ad.value(x).dims;
};

var concat = function(arr) {
  var t = T.concat(arr);
  return T.reshape(t, [dims(t)[0], 1]);
};

var sigmoid = function(x) {
  return T.sigmoid(x);
};

var tanh = function(x) {
  return T.tanh(x);
};

// Compose several functions in left to right order.
// stack([f, g, h]) == compose(compose(h, g), f)
var stack = function(arr) {
  var iter = function(i) {
    return (arr.length === i) ?
        idF :
        compose(iter(i + 1), arr[i]);
  };
  return iter(0);
};

// When a network is used in the model we often want to include a
// prior over the network's parameters. (So that we're specifying
// fully probabilistic model that could in principle be used with any
// inference algorithm.)

// In order that neural network helpers can be reused in both the
// model and the guide, we need to abstract out the specification of
// the prior and its guide distribution.

// This is done using the model parameter scheme described above.
// Specifically, the neural network constructors take as an argument
// the function that is used to create/fetch parameters. If this
// function is `param` then we end up with a net suitable for use in
// the guide. Alternatively a parameter model function can be passed
// to create a net suitable for use in the model.

// TODO: Write about the problems that arise in taking this approach.

// The biggest problem I see with this approach is inherited from
// `param`. I'll describe the problem with that, the problem with nets
// is similar. A parameter is created/fetched with something like
// `param({name, dims, init})`. Note, we can induce parameter sharing
// by reusing a name more than once. The problem is that when sharing
// is across two or more distinct locations in source code, then there
// is no longer a single canonical location in which dims (and other
// properties) are specified. (The dims from the `param` call
// encountered first will be used.) At best this is an annoyance
// (because the easiest way to cope is to use the same dims at every
// occurrence of a name), but I suspect that in practice it will be
// worse than annoying. A bug arising as a result of a tensor getting
// unexpected dims by virtue of a definition somewhere else in the
// program will, I suspect, cause much confusion. (Especially if the
// sharing by name is accidental, or worse, caused by loading a
// package!) I think this problem stems from the fact that `param`
// smushes together both creation and retrieval of parameters.
// Splitting apart these two operations would offer a number of ways
// of addressing this I think.

var linear = function(nout, name, maybeParamModel) {
  var nnparam = maybeParamModel || param;
  assert.ok(Number.isInteger(nout), 'nout should be an integer.');
  assert.ok(name, 'A network must be given a name');
  return function(x) {
    var nin = dims(x)[0];
    var sigma = Math.sqrt(2 / (nin + nout));
    var w = nnparam({name, dims: [nout, nin], sigma});
    return T.dot(w, x);
  };
};

var bias = function(name, maybeParamModel) {
  assert.ok(name, 'A network must be given a name');
  var nnparam = maybeParamModel || param;
  return function(x) {
    var nout = dims(x)[0];
    var b = nnparam({name, dims: [nout, 1], sigma: 0});
    return T.add(x, b);
  };
};

var affine = function(nout, name, maybeParamModel) {
  return compose(
    bias(name + 'b', maybeParamModel),
    linear(nout, name + 'w', maybeParamModel));
};

// Center and rescale the input. Typical usage is to put this after a
// linear layer and follow it with a bias and non-linearity, yielding
// "Layer normalization".

// https://arxiv.org/abs/1607.06450

var layerNorm = function(name, maybeParamModel) {
  var nnparam = maybeParamModel || param;
  assert.ok(name, 'A network must be given a name');
  return function(a) {
    var nout = dims(a)[0];
    // Gain parameters.
    var g = nnparam({name: name + 'g', dims: [nout, 1], mu: 1, sigma: 0});
    var mu = T.sumreduce(a) / nout;
    var acentered = T.sub(a, mu);
    var sd = Math.sqrt(T.sumreduce(T.pow(acentered, 2)) / nout);
    assert.ok(ad.value(sd) > 0, 'Standard deviation of activations is not positive');
    return T.mul(T.div(g, sd), acentered);
  };
};

// TODO: You can imagine having a convenient way to do a restricted
// kind of composition of network constructors, where we assume the
// sub nets are stacked, and each take the same nout param. (Also
// requires more consistency in the interface of current constructors,
// e.g. we'd need to do something i like have a version of bias that
// takes a dummy nout param.) This could be useful for passing novel
// constructors to gru/lstm etc.

var affineWithLayerNorm = function(nout, name, maybeModelParam) {
  var nnparam = maybeModelParam || param;
  assert.ok(name, 'A network must be given a name');
  return stack([
    linear(nout, name + 'w', nnparam),
    layerNorm(name + 'ln', nnparam),
    bias(name + 'b', nnparam)
  ]);
};

// TODO: Implement in a similar way to layer norm.

// Linear layer with weight normalization.
// https://arxiv.org/abs/1602.07868

// It's not clear how we could do the data dependent init., so we
// resort to Xavier initialization. Is this sensible? The problem is
// this might be used as part of a recurrent net (which is problematic
// for the reason mentioned in the paper) and because we don't have a
// straight-forward way of looking at a 'batch' from here.

// Does it make sense to apply regularization v here, given that we
// already normalize the length of the row vectors of v? In practice,
// regularization seems to have a much stronger effect on this
// parameterization. (You can see this with L2 prior by comparing this
// with the linear layer on the ml-classifier example.) Removing the
// prior from v seems to make a difference here.

// Note: When I tried parameterizing g in log space the ml-classifier
// example often failed to work well. I don't know why.

var linearWeightNorm = function(nout, name, maybeParamModel) {
  var nnparam = maybeParamModel || param;
  assert.ok(Number.isInteger(nout), 'nout should be an integer');
  assert.ok(name, 'A network must be given a name');
  return function(x) {
    var nin = dims(x)[0];
    var sigma = Math.sqrt(2 / (nin + nout));
    var g = nnparam({name: name + 'g', dims: [nout, 1], mu: 1, sigma: 0}); // gain
    var v = nnparam({name: name + 'v', dims: [nout, nin], sigma});
    var b = nnparam({name: name + 'b', dims: [nout, 1], sigma: 0});
    var norm = T.sqrt(webpplNn.sumreduce0(T.pow(v, 2)));
    return T.add(T.mul(T.div(g, norm), T.dot(v, x)), b);
  };
};

// Gated Recurrent Unit

// This is similar to the variant described in "Empirical Evaluation
// of Gated Recurrent Neural Networks on Sequence Modeling", which
// computes the candidate activation in a slightly different way from
// the original paper.

// https://arxiv.org/abs/1412.3555

var gru = function(dim, name, maybeParamModel, maybeMakeNet) {
  assert.ok(Number.isInteger(dim), 'dim should be an integer');
  assert.ok(name, 'A network must be given a name');
  var nnparam = maybeParamModel || param;
  var makeNet = maybeMakeNet || affine;
  var update = compose(sigmoid, makeNet(dim, name + 'update', nnparam));
  var reset = compose(sigmoid, makeNet(dim, name + 'reset', nnparam));
  var candidate = compose(tanh, makeNet(dim, name + 'candidate', nnparam));
  return function(hprev, x) {
    assert.ok(dims(hprev)[0] === dim,
              'Previous hidden vector has unexpected dimension');
    var hprevx = concat([hprev, x]);
    var r = reset(hprevx);
    var z = update(hprevx);
    var cand = candidate(concat([T.mul(hprev, r), x]));
    var oneminusz = T.add(T.neg(z), 1);
    return T.add(T.mul(oneminusz, hprev), T.mul(z, cand));
  };
};

// Long Short Term Memory

// This is similar to the variant described in "Generating sequences
// with recurrent neural networks" (Graves 2013). The difference is
// that here there are no 'peep-hole' connections. i.e. The previous
// memory state is not (currently) passed as input to the forget,
// input, output gates.

// https://arxiv.org/abs/1308.0850

var lstm = function(dim, name, maybeParamModel, maybeMakeNet) {
  // dim is the total dimension of the state. i.e. memory + hidden
  // state vectors. Setting things up this way makes it easy to swap
  // between gru and lstm.
  assert.ok(Number.isInteger(dim), 'dim should be an integer');
  assert.ok(dim % 2 === 0, 'dim should be an even integer');
  assert.ok(name, 'A network must be given a name');
  var hdim = dim / 2;
  var nnparam = maybeParamModel || param;
  var makeNet = maybeMakeNet || affine;
  var forget = compose(sigmoid, makeNet(hdim, name + 'forget', nnparam));
  var input = compose(sigmoid, makeNet(hdim, name + 'input', nnparam));
  var output = compose(sigmoid, makeNet(hdim, name + 'output', nnparam));
  var candidate = compose(tanh, makeNet(hdim, name + 'candidate', nnparam));
  return function(prev, x) {
    // For compatibility with the interface of e.g. gru we combine the
    // memory and hidden state into a single vector, prev.
    assert.ok(dims(prev)[0] === dim,
              'Previous state vector has unexpected dimension');
    var cprev = T.reshape(T.range(prev, 0, hdim), [hdim, 1]);
    var hprev = T.reshape(T.range(prev, hdim, dim), [hdim, 1]);
    var hprevx = concat([hprev, x]);
    // TODO: It's said that initializing the biases of the forget gate
    // to one is a good idea. This is so that the output is close to
    // one at the start of optimization, ensuring information is
    // passed along. This is mentioned in e.g. "An Empirical
    // Exploration of Recurrent Network Architectures".
    var f = forget(hprevx);
    var i = input(hprevx);
    var o = output(hprevx);
    var cand = candidate(hprevx);
    var c = T.add(T.mul(f, cprev), T.mul(i, cand));
    var h = T.mul(o, tanh(c));
    return concat([c, h]);
  };
};
